# covid_severity_Prediction

### Predicting Severity of COVID-19 Cases

###Data Processing

Data processing in machine learning is a critical step required to increase the quality of data. This is done by preparing (cleaning and organizing) raw data into an understandable and readable format suitable for building and training machine learning models. The dataset provided is a COVID dataset in CSV format with 126 rows and 19476 columns. It has categorical attributes such as Sex, Severity, Age, and genome sequences that are continuous variables. There are no null values present in the dataset. In this case, Severity being our target/dependent variable and categorical in the nature of NonICU and ICU will be encoded into numeric values 0 and 1, respectively, as machine learning algorithms perform best with numeric values. The dataset also shows the continuous variable (genomes), which is our independent variable, which has values that vary in different ranges, which can affect the efficiency of our model. Normalization and Standardization will therefore be applied to enable the dataset to have a common scale and get a normal distribution of the dataset. By this, the mean of the dataset will be made 0, and the standard deviation equivalent to 1. The large nature of our predictors will require that we perform the Principal Component Analysis (PCA) to reduce the dimensionality of data while retaining as much information as possible to enhance the model's performance.

###Training and tuning
The given dataset contains 19476 columns, where 19472 columns are genome sequences corresponding to a sample of a person of a certain age and gender. These predictors, which include the genome sequences, are required to classify the Severity for that sample, whether it is a Non-ICU or an ICU case. Since this analysis involves classification of Severity, a supervised learning algorithm for Classification needs to be applied. Logistic Regression is the supervised learning algorithm that will be used to classify the Severity of the sample. The data, including the Sex, Age, and genome sequences reduced to 60 components using PCA, will be used to train and test the model. 80% of this data will be the training data, and the rest 20% will be used as the unseen test data. This model can be validated using k-fold cross validation later to validate the accuracy of this model using different folds of the data. Hyperparameter tuning will be implemented to find the best parameters to train the model. The behavior of a machine learning model can be under control by tuning the best parameters. GridSearchCV is one of the most common hyperparameter tuning techniques to fine-tune the parameters, where we provide a list of parameters, and each combination of those provided values is created to train models and see which combination(grid) provides the most accuracy. The combination that provides the best result of all the combinations is chosen as the hyperparameters which we use to train our actual model. For instance, C=0.08858667904100823, max_iter=100, penalty='l1', solver='liblinear' are some of the hyperparameters that GridSearchCV computed for Logistic Regression for the dataset used in this analysis.

###Model validation
In addition to using k-fold cross-validation, various evaluation metrics will also be used to validate the model. The first metric that will be used is Accuracy, which is defined by R^2. R^2 will define how close our model is to the regression line. A higher R^2 indicates good accuracy of the model. This metric will be used to see if the proposed model will be a good fit to predict the Severity of the COVID-19 cases. Secondly, Mean Squared Error (MSE) is calculated by taking the average of the sum of the squares of Errors. This metric is used as it shows how far the model's predictions are from the actual data points. A small MSE corresponds to an excellent fit to the dataset with accurate predictions, whereas a large MSE denotes highly inaccurate predictions which are far from the actual values. The proposed model's MSE will determine the number of errors in the predictions. To add on, Precision, Recall, and f-score will also be used to evaluate the model. Precision will measure the ratio of True Positives to the Total of the predicted Positive Classes (True Positive + False Positive), while Recall will measure the ratio of True Positives to the Total of the actual Positive Classes (True Positive + False Negative). The f-score is a combined mean of Precision and Recall, ranging between 0 and 1 (SciKit Learn, 2021). A high Precision, Recall, and f-score is desirable as it indicates good accuracy of the model. 

###Model interpretation
Logistic Regression can be interpreted and predicted using β coefficients.β coefficients can be determined using function pipe[1].coef_. The higher the value of β coefficients (in absolute value), the higher the probability of predicting a positive outcome of 'Severity'. β coefficients can be interpreted as slopes transformed with the help of the logit function. Logistic Regression models the logit transformed probability as a linear relationship with predictor variables. β coefficients can easily be visualized using Seaborn. The β coefficients are stable only if the training data does not have multicollinearity.
The major problem while training a dataset is overfitting and underfitting. Overfitting occurs when the training model learns the pattern and noise in the train data to the extent that it affects the performance of the test data model and underfitting occurs when the model neither learns nor generalizes well on the test dataset. A perfect model should be good in estimating the distribution and probability in the train data as well as the test data. Model overfitting can be avoided using methods such as K-fold cross-validation and hyperparameter tuning. In K-fold cross-validation, the dataset is divided into three parts. The training part contains 80% data, and the test part contains 20% data. The training dataset is further subdivided into an 80:20 ratio, and 80% of data can be used for training and 20% for cross-validation. This will help to monitor the train data to validate the model on unseen data. The model is not overfitting if the training and testing accuracy is close. If the training accuracy is excellent and the test accuracy is poor, then the model will be overfitted and vice versa. If the model is underfitting or overfitting, the hyperparameter values will re-train the model until we get a good fit. In hyperparameter tuning, the cross-validation accuracy on all the possible combinations of hyperparameters is checked. The combination that gives the best accuracy is selected, and the model is trained with the selected hyperparameters and then tested. 
                                                   
                                                   ###Predictions
Predicting a future event is an essential aspect of machine learning. Predictions deal with input observations to learn the unknown pattern by making predictions on unseen data. The training data will be used to train the model. Once the model is trained, it will be used to predict the Severity of the unseen test data.
In order to improve the model's performance,  the data will be split using the train_test_split function in a ratio of 80:20. A confusion matrix heatmap will be plotted to check the predictive model's performance, and accuracy score and precision will be checked. The higher the accuracy score, the better the prediction model (Waseem, 2022). The confusion matrix can show the number of observations correctly classified. If a classification accuracy of 70 percent and above is obtained, the model is set to fit the data accurately (GeeksforGeeks, 2022). This model can then successfully predict the Severity of parents admitted with COVID cases.


###Bibliography 
[1] Data science in action. W Van Der Aalst - Process mining, 2016 – Springer.
[2] Data science and its relationship to big data and data-driven decision making. F Provost, T Fawcett - Big data, 2013.
[3] Data Science for Business: What you need to know about data mining and data-analytic thinking. F Provost, T Fawcett – 2013.
[4]. UpGrad blog. (2020). Data Preprocessing in Machine Learning: [online] Available at: https://www.upgrad.com/blog/data-preprocessing-in-machine-learning/.
[4] SciKit Learn (2021) sklearn.metrics.f1_score. Available at: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html (Accessed: 17 January 2022).
[5] Waseem, M., 2022. Logistic Regression In Python | Python For Data Science | Edureka. [online] Edureka. Available at: <https://www.edureka.co/blog/logistic-regression-in-python/amp/> [Accessed 19 January 2022].
[6] Geeksforgeeks.org. 2022. ML | Logistic Regression using Python - GeeksforGeeks. [online] Available at: <https://www.geeksforgeeks.org/ml-logistic-regression-using-python/amp/> [Accessed 19 January 2022].
